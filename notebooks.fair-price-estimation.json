{"version":3,"kind":"Notebook","sha256":"0877ea6b5615327e20517a91620ce0ca26c0164c1a3edf54fc2c160d56f721a7","slug":"notebooks.fair-price-estimation","location":"/notebooks/fair_price_estimation.ipynb","dependencies":[],"frontmatter":{"title":"Fair Price Estimation","content_includes_title":true,"kernelspec":{"name":"python3","display_name":"base","language":"python"},"authors":[{"nameParsed":{"literal":"Javier Sabio González","given":"Javier Sabio","family":"González"},"name":"Javier Sabio González","id":"contributors-myst-generated-uid-0"}],"github":"https://xaviweise.github.io/aaat/","numbering":{"title":{"offset":1}},"source_url":"https://xaviweise.github.io/aaat//blob/main/notebooks/fair_price_estimation.ipynb","edit_url":"https://xaviweise.github.io/aaat//edit/main/notebooks/fair_price_estimation.ipynb","exports":[{"format":"ipynb","filename":"fair_price_estimation.ipynb","url":"/build/fair_price_estimatio-ac91252b8780d4a3bd9282a46404873e.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[],"key":"s54yXdldsr"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":1,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fair Price Estimation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ACRY32WY1D"}],"identifier":"fair-price-estimation","label":"Fair Price Estimation","html_id":"fair-price-estimation","implicit":true,"key":"WNxDHjlPRo"}],"key":"OfVWqoUlvD"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Pricing of flow products","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"P96eFb5PmX"}],"identifier":"pricing-of-flow-products","label":"Pricing of flow products","html_id":"pricing-of-flow-products","implicit":true,"key":"YbbVOJkcCl"},{"type":"heading","depth":3,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The Kalman Filter model for pricing","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Id5Nvzv9Jv"}],"identifier":"the-kalman-filter-model-for-pricing","label":"The Kalman Filter model for pricing","html_id":"the-kalman-filter-model-for-pricing","implicit":true,"key":"nVeOz8cFP3"}],"key":"hD9VOjOy1W"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Compromise execution: run full algorithm but with fewer timesteps/day so it completes here.\n# Use 22 days × 60 steps/day = 1320 timesteps (faster but pattern preserved).\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(100)\n\ndef make_obs_pattern(days=22, steps_per_day=60):\n    pattern = []\n    for _ in range(days):\n        base = steps_per_day // 3\n        rem = steps_per_day - 3 * base\n        for _ in range(base): pattern.append(np.array([1, 0], dtype=bool))\n        for _ in range(base): pattern.append(np.array([1, 1], dtype=bool))\n        for _ in range(base + rem): pattern.append(np.array([0, 1], dtype=bool))\n    return np.array(pattern)\n\ndef simulate_continuous_trades(Q, R, obs_pattern):\n    # Q is the covariance matrix of the mid-price process\n    # R is the covariance matrix of the observation process\n    T = len(obs_pattern); n = Q.shape[0]\n    mids = np.zeros((T, n)); trades = np.zeros((T,n))\n    for t in range(1, T):\n        mids[t] = mids[t-1] + np.random.multivariate_normal(np.zeros(n), Q)\n    for t in range(T):\n        trades[t] = mids[t] + np.random.multivariate_normal(np.zeros(n), R)\n    return mids, trades\n\ndef kalman_filter_timevarying(y, R_time, A, Q, x0=None, P0=None):\n    T = y.shape[0]; n = A.shape[0]\n    xs = np.zeros((T, n)); Ps = np.zeros((T, n, n))\n    if x0 is None: x0 = np.zeros(n)\n    if P0 is None: P0 = np.eye(n)\n    x_pred = x0.copy(); P_pred = P0.copy()\n    for t in range(T):\n        R_t = R_time[t]\n        S = P_pred + R_t + np.eye(n)*1e-12\n        K = P_pred @ np.linalg.inv(S)\n        innov = y[t] - x_pred\n        x_upd = x_pred + K @ innov\n        P_upd = (np.eye(n) - K) @ P_pred\n        xs[t] = x_upd; Ps[t] = P_upd\n        x_pred = A @ x_upd\n        P_pred = A @ P_upd @ A.T + Q\n    return xs, Ps\n\ndef rts_smoother(xs, Ps, A, Q):\n    T, n = xs.shape\n    x_s = np.zeros_like(xs); P_s = np.zeros_like(Ps)\n    x_s[-1] = xs[-1].copy(); P_s[-1] = Ps[-1].copy()\n    for t in range(T-2, -1, -1):\n        P_pred = A @ Ps[t] @ A.T + Q + np.eye(n)*1e-12\n        J = Ps[t] @ A.T @ np.linalg.inv(P_pred)\n        x_s[t] = xs[t] + J @ (x_s[t+1] - A @ xs[t])\n        P_s[t] = Ps[t] + J @ (P_s[t+1] - P_pred) @ J.T\n    return x_s, P_s\n\ndef em_timevaryingR(y, obs_pattern, A, large_R=1e8, max_iter=25, tol=1e-6):\n    T, n = y.shape\n    Q = np.eye(n) * 1e-4\n    R_diag = np.array([1e-3, 2e-3])\n    prev_ll = -np.inf; history = []\n    for it in range(max_iter):\n        R_time = np.zeros((T,n,n))\n        for t in range(T):\n            diag = np.array([R_diag[i] if obs_pattern[t,i] else large_R for i in range(n)])\n            R_time[t] = np.diag(diag)\n        xs_filt, Ps_filt = kalman_filter_timevarying(y, R_time, A, Q)\n        xs_smooth, Ps_smooth = rts_smoother(xs_filt, Ps_filt, A, Q)\n        Exx = Ps_smooth + np.einsum('ti,tj->tij', xs_smooth, xs_smooth)\n        Exx_lag = np.zeros((T-1,n,n))\n        for t in range(1,T):\n            P_pred = A @ Ps_filt[t-1] @ A.T + Q\n            J = Ps_filt[t-1] @ A.T @ np.linalg.inv(P_pred + np.eye(n)*1e-12)\n            P_t_t1 = J @ Ps_smooth[t]\n            Exx_lag[t-1] = P_t_t1 + np.outer(xs_smooth[t], xs_smooth[t-1])\n        sumQ = np.zeros((n,n))\n        for t in range(1,T):\n            sumQ += Exx[t] - Exx_lag[t-1] - Exx_lag[t-1].T + Exx[t-1]\n        Q_new = (sumQ / (T-1) + sumQ.T / (T-1)) / 2\n        R_new = np.zeros(n); counts = np.zeros(n,dtype=int)\n        for t in range(T):\n            for i in range(n):\n                if obs_pattern[t,i]:\n                    y_i = y[t,i]; Ex_i = xs_smooth[t,i]; Exx_ii = Exx[t,i,i]\n                    R_new[i] += (y_i*y_i - 2*y_i*Ex_i + Exx_ii)\n                    counts[i] += 1\n        for i in range(n):\n            if counts[i]>0:\n                R_new[i] = R_new[i] / counts[i]\n            else:\n                R_new[i] = R_diag[i]\n        Q_new += np.eye(n)*1e-12\n        R_new = np.maximum(R_new, 1e-12)\n        Q = 0.7*Q + 0.3*Q_new\n        R_diag = 0.7*R_diag + 0.3*R_new\n        history.append((Q.copy(), R_diag.copy()))\n        # approx ll\n        ll = 0.0; x_pred = np.zeros(n); P_pred = np.eye(n)\n        for t in range(T):\n            R_t = np.diag([R_diag[i] if obs_pattern[t,i] else large_R for i in range(n)])\n            S = P_pred + R_t + np.eye(n)*1e-12\n            innov = y[t] - x_pred\n            invS = np.linalg.inv(S)\n            ll += -0.5*(np.log(np.linalg.det(2*np.pi*S)) + innov.T @ invS @ innov)\n            K = P_pred @ invS\n            x_upd = x_pred + K @ innov\n            P_upd = (np.eye(n) - K) @ P_pred\n            x_pred = A @ x_upd\n            P_pred = A @ P_upd @ A.T + Q\n        if it>0 and abs(ll - prev_ll) < tol:\n            break\n        prev_ll = ll\n    return Q, np.diag(R_diag), history, ll\n\n# Run with 22 days x 60 steps/day\ndays = 22; steps_per_day = 60\nobs_pattern = make_obs_pattern(days, steps_per_day); T = len(obs_pattern)\n# Parameters\nrho = 0.9   # correlation\nsigma1 = np.sqrt(5e-4)   # std of instrument 1\nsigma2 = np.sqrt(4e-4)   # std of instrument 2\n# Construct covariance matrix\nQ_true = np.array([\n    [sigma1**2, rho * sigma1 * sigma2],\n    [rho * sigma1 * sigma2, sigma2**2]\n]) # We make transition covariance non-diagonal\nR_true = np.diag([1e-3,2e-3]) # We make observation covariance diagonal\nmids_true, trades = simulate_continuous_trades(Q_true, R_true, obs_pattern)\nT_half = T//2; y_train = trades[:T_half]; y_test = trades[T_half:]\nobs_train = obs_pattern[:T_half]; obs_test = obs_pattern[T_half:]\nmids_test = mids_true[T_half:]; A = np.eye(2)\n\nQ_est, R_est, history, ll_final = em_timevaryingR(y_train, obs_train, A, large_R=1e8, max_iter=25, tol=1e-5)\ndef build_R_time_from_diag(R_diag, obs_pattern, large_R=1e8):\n    T = len(obs_pattern); n = len(R_diag); R_time = np.zeros((T,n,n))\n    for t in range(T):\n        diag = np.array([R_diag[i] if obs_pattern[t,i] else large_R for i in range(n)])\n        R_time[t] = np.diag(diag)\n    return R_time\nR_time_test = build_R_time_from_diag(np.diag(R_est), obs_test, large_R=1e8)\nmids_est, _ = kalman_filter_timevarying(y_test, R_time_test, A, Q_est)\nrmse = np.sqrt(np.mean((mids_est - mids_test)**2, axis=0))\n\nprint(\"T (timesteps):\", T)\nprint(\"True Q:\\n\", Q_true)\nprint(\"Estimated Q:\\n\", Q_est)\nprint(\"True R diag:\", np.diag(R_true))\nprint(\"Estimated R diag:\", np.diag(R_est))\nprint(\"Final approx loglik:\", ll_final)\nprint(\"RMSE on second half:\", rmse)\n\n# Plot window without showing trades when market closed\nplt.figure(figsize=(14, 8))\nw0 = 200\nw1 = min(w0 + 200, y_test.shape[0])\nt = np.arange(T_half + w0, T_half + w1)\n\n# Rerun filter on test to get covariance sequence for error bars\nmids_est, Ps_est = kalman_filter_timevarying(y_test, R_time_test, A, Q_est)\n\n# Extract ±1 std from diagonal of P (filter uncertainty)\nstds = np.sqrt(np.array([np.diag(P) for P in Ps_est]))\n\n# --- Instrument 1 ---\nplt.subplot(2, 1, 1)\nplt.plot(t, mids_test[w0:w1, 0], label='True mid 1', lw=2)\nplt.plot(t, mids_est[w0:w1, 0], label='Estimated mid 1', lw=1.5, ls='--')\nplt.fill_between(\n    t,\n    mids_est[w0:w1, 0] - stds[w0:w1, 0],\n    mids_est[w0:w1, 0] + stds[w0:w1, 0],\n    color='gray', alpha=0.2, label='±1 std (KF)'\n)\nmask_plot = obs_test[w0:w1, 0]\nplt.scatter(t[mask_plot], y_test[w0:w1, 0][mask_plot],\n            s=8, label='Trades 1 (open)', alpha=0.6)\nplt.title('Instrument 1')\nplt.legend()\n\n# --- Instrument 2 ---\nplt.subplot(2, 1, 2)\nplt.plot(t, mids_test[w0:w1, 1], label='True mid 2', lw=2)\nplt.plot(t, mids_est[w0:w1, 1], label='Estimated mid 2', lw=1.5, ls='--')\nplt.fill_between(\n    t,\n    mids_est[w0:w1, 1] - stds[w0:w1, 1],\n    mids_est[w0:w1, 1] + stds[w0:w1, 1],\n    color='gray', alpha=0.2, label='±1 std (KF)'\n)\nmask_plot1 = obs_test[w0:w1, 1]\nplt.scatter(t[mask_plot1], y_test[w0:w1, 1][mask_plot1],\n            s=8, label='Trades 2 (open)', alpha=0.6)\nplt.title('Instrument 2')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n","key":"po967Bjmvv"},{"type":"outputs","id":"8JK2KXUxKt9u7EocWBRLE","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"T (timesteps): 1320\nTrue Q:\n [[0.0005     0.00040249]\n [0.00040249 0.0004    ]]\nEstimated Q:\n [[0.00031037 0.0001628 ]\n [0.0001628  0.00022782]]\nTrue R diag: [0.001 0.002]\nEstimated R diag: [0.00117355 0.00253554]\nFinal approx loglik: -3121.7461477103247\nRMSE on second half: [0.03244913 0.09017213]\n"},"children":[],"key":"FYbapxkPQw"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"98bd8bd742243ae50dd6f3cfb65dd6de","path":"/build/98bd8bd742243ae50dd6f3cfb65dd6de.png"},"text/plain":{"content":"<Figure size 1400x800 with 2 Axes>","content_type":"text/plain"}}},"children":[],"key":"m4zHfMmvUv"}],"key":"sArk1ETDvA"}],"key":"r9ciXDO4zV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The utility indifference theory for derivatives pricing","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Gyr4twIBID"}],"identifier":"the-utility-indifference-theory-for-derivatives-pricing","label":"The utility indifference theory for derivatives pricing","html_id":"the-utility-indifference-theory-for-derivatives-pricing","implicit":true,"key":"anigq35pXR"}],"key":"bpkMmonVRN"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Call option premium using the utility indifference principle","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GbqJuhpCEP"}],"identifier":"call-option-premium-using-the-utility-indifference-principle","label":"Call option premium using the utility indifference principle","html_id":"call-option-premium-using-the-utility-indifference-principle","implicit":true,"key":"fwcCZqAXiD"}],"key":"hSAAdVjzes"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Black-Scholes formula with drift implementation\ndef black_scholes_with_drift(S, K, T, t, r, mu, sigma):\n    d1_mu = (np.log(S / K) + (mu + 0.5 * sigma**2) * (T - t)) / (sigma * np.sqrt(T - t))\n    d2_mu = d1_mu - sigma * np.sqrt(T - t)\n    call_price_with_drift = S * np.exp((mu - r) * (T - t)) * norm.cdf(d1_mu) - K * np.exp(-r * (T - t)) * norm.cdf(d2_mu)\n    return call_price_with_drift\n\n# Parameters for the plots\nS_t = 100   # Current stock price\nK = 100     # Strike price\nT = 1       # Time to maturity (1 year)\nt = 0       # Current time (now)\nr = 0.05    # Risk-free interest rate (5%)\nmu = 0.1    # Drift rate (10%)\nsigma = 0.2 # Volatility (20%)\n\n# Generate data for each dependency plot\nS_values = np.linspace(50, 150, 400)\nK_values = np.linspace(50, 150, 400)\nT_values = np.linspace(0.01, 2, 400)\nr_values = np.linspace(0, 0.2, 400)\nsigma_values = np.linspace(0.01, 1, 400)\nmu_values = np.linspace(-0.1, 0.3, 400)\n\n# Calculate call prices with drift\nC_S_drift = [black_scholes_with_drift(S, K, T, t, r, mu, sigma) for S in S_values]\nC_K_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for K in K_values]\nC_T_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for T in T_values]\nC_r_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for r in r_values]\nC_sigma_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for sigma in sigma_values]\nC_mu_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for mu in mu_values]\n\n# Plotting all dependencies in a single figure for export\n\nfig, axs = plt.subplots(3, 2, figsize=(15, 18))\n\n# Current Stock Price (S) with Drift\naxs[0, 0].plot(S_values, C_S_drift)\naxs[0, 0].set_title('Call Option Price vs Current Stock Price (S) with Drift')\naxs[0, 0].set_xlabel('Current Stock Price (S)')\naxs[0, 0].set_ylabel('Call Option Price (P)')\naxs[0, 0].grid(True)\n\n# Strike Price (K) with Drift\naxs[0, 1].plot(K_values, C_K_drift)\naxs[0, 1].set_title('Call Option Price vs Strike Price (K) with Drift')\naxs[0, 1].set_xlabel('Strike Price (K)')\naxs[0, 1].set_ylabel('Call Option Price (P)')\naxs[0, 1].grid(True)\n\n# Time to Maturity (T) with Drift\naxs[1, 0].plot(T_values, C_T_drift)\naxs[1, 0].set_title('Call Option Price vs Time to Maturity (T) with Drift')\naxs[1, 0].set_xlabel('Time to Maturity (T)')\naxs[1, 0].set_ylabel('Call Option Price (P)')\naxs[1, 0].grid(True)\n\n# Risk-Free Interest Rate (r) with Drift\naxs[1, 1].plot(r_values, C_r_drift)\naxs[1, 1].set_title('Call Option Price vs Risk-Free Interest Rate (r) with Drift')\naxs[1, 1].set_xlabel('Risk-Free Interest Rate (r)')\naxs[1, 1].set_ylabel('Call Option Price (P)')\naxs[1, 1].grid(True)\n\n# Volatility (σ) with Drift\naxs[2, 0].plot(sigma_values, C_sigma_drift)\naxs[2, 0].set_title('Call Option Price vs Volatility (σ) with Drift')\naxs[2, 0].set_xlabel('Volatility (σ)')\naxs[2, 0].set_ylabel('Call Option Price (P)')\naxs[2, 0].grid(True)\n\n# Drift (μ)\naxs[2, 1].plot(mu_values, C_mu_drift)\naxs[2, 1].set_title('Call Option Price vs Drift (μ)')\naxs[2, 1].set_xlabel('Drift (μ)')\naxs[2, 1].set_ylabel('Call Option Price (P)')\naxs[2, 1].grid(True)","key":"AZK7VQhwaY"},{"type":"outputs","id":"4Q34qSlpUYeDGl0Fkx6qa","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0357c4253a819a842cf3941221e4e212","path":"/build/0357c4253a819a842cf3941221e4e212.png"},"text/plain":{"content":"<Figure size 1500x1800 with 6 Axes>","content_type":"text/plain"}}},"children":[],"key":"HfosbmlKlY"}],"key":"oDqPd2AkKx"}],"key":"tCKpw72bRv"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The arbitrage-free theory of derivatives pricing","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cjRBPlaXLF"}],"identifier":"the-arbitrage-free-theory-of-derivatives-pricing","label":"The arbitrage-free theory of derivatives pricing","html_id":"the-arbitrage-free-theory-of-derivatives-pricing","implicit":true,"key":"ktOaHoecgu"}],"key":"Q1SqssuMuu"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Call option premium using arbitrage-free theory","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SFG2SJE6iC"}],"identifier":"call-option-premium-using-arbitrage-free-theory","label":"Call option premium using arbitrage-free theory","html_id":"call-option-premium-using-arbitrage-free-theory","implicit":true,"key":"JJ65TUPNYY"}],"key":"qXk8phEJLx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Black-Scholes formula with drift implementation\ndef black_scholes_with_drift(S, K, T, t, r, mu, sigma):\n    d1_mu = (np.log(S / K) + (mu + 0.5 * sigma**2) * (T - t)) / (sigma * np.sqrt(T - t))\n    d2_mu = d1_mu - sigma * np.sqrt(T - t)\n    call_price_with_drift = S * np.exp((mu - r) * (T - t)) * norm.cdf(d1_mu) - K * np.exp(-r * (T - t)) * norm.cdf(d2_mu)\n    return call_price_with_drift\n\n# Standard Black-Scholes formula (mu = r)\ndef black_scholes_standard(S, K, T, t, r, sigma):\n    return black_scholes_with_drift(S, K, T, t, r, r, sigma)\n\n# Parameters for the plots\nS_t = 100   # Current stock price\nK = 100     # Strike price\nT = 1       # Time to maturity (1 year)\nt = 0       # Current time (now)\nr = 0.05    # Risk-free interest rate (5%)\nmu = 0.1    # Drift rate (10%)\nsigma = 0.2 # Volatility (20%)\n\n# Generate data for each dependency plot\nS_values = np.linspace(50, 150, 400)\nK_values = np.linspace(50, 150, 400)\nT_values = np.linspace(0.01, 2, 400)\nr_values = np.linspace(0, 0.2, 400)\nsigma_values = np.linspace(0.01, 1, 400)\nmu_values = np.linspace(-0.1, 0.3, 400)\n\n# Calculate call prices with drift\nC_S_drift = [black_scholes_with_drift(S, K, T, t, r, mu, sigma) for S in S_values]\nC_K_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for K in K_values]\nC_T_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for T in T_values]\nC_r_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for r in r_values]\nC_sigma_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for sigma in sigma_values]\nC_mu_drift = [black_scholes_with_drift(S_t, K, T, t, r, mu, sigma) for mu in mu_values]\n\n# Calculate call prices using standard Black-Scholes formula (mu = r)\nC_S_standard = [black_scholes_standard(S, K, T, t, r, sigma) for S in S_values]\nC_K_standard = [black_scholes_standard(S_t, K, T, t, r, sigma) for K in K_values]\nC_T_standard = [black_scholes_standard(S_t, K, T, t, r, sigma) for T in T_values]\nC_r_standard = [black_scholes_standard(S_t, K, T, t, r, sigma) for r in r_values]\nC_sigma_standard = [black_scholes_standard(S_t, K, T, t, r, sigma) for sigma in sigma_values]\nC_mu_standard = [black_scholes_standard(S_t, K, T, t, r, sigma) for mu in mu_values]\n\n# Plotting all dependencies in a single figure for comparison\nfig, axs = plt.subplots(3, 2, figsize=(15, 18))\n\n# Current Stock Price (S) comparison\naxs[0, 0].plot(S_values, C_S_drift, label=\"With Drift (mu = 0.1)\")\naxs[0, 0].plot(S_values, C_S_standard, label=\"Standard (mu = r)\", linestyle=\"--\")\naxs[0, 0].set_title('Call Option Price vs Current Stock Price (S)')\naxs[0, 0].set_xlabel('Current Stock Price (S)')\naxs[0, 0].set_ylabel('Call Option Price (P)')\naxs[0, 0].legend()\naxs[0, 0].grid(True)\n\n# Strike Price (K) comparison\naxs[0, 1].plot(K_values, C_K_drift, label=\"With Drift (mu = 0.1)\")\naxs[0, 1].plot(K_values, C_K_standard, label=\"Standard (mu = r)\", linestyle=\"--\")\naxs[0, 1].set_title('Call Option Price vs Strike Price (K)')\naxs[0, 1].set_xlabel('Strike Price (K)')\naxs[0, 1].set_ylabel('Call Option Price (P)')\naxs[0, 1].legend()\naxs[0, 1].grid(True)\n\n# Time to Maturity (T) comparison\naxs[1, 0].plot(T_values, C_T_drift, label=\"With Drift (mu = 0.1)\")\naxs[1, 0].plot(T_values, C_T_standard, label=\"Standard (mu = r)\", linestyle=\"--\")\naxs[1, 0].set_title('Call Option Price vs Time to Maturity (T)')\naxs[1, 0].set_xlabel('Time to Maturity (T)')\naxs[1, 0].set_ylabel('Call Option Price (P)')\naxs[1, 0].legend()\naxs[1, 0].grid(True)\n\n# Risk-Free Interest Rate (r) comparison\naxs[1, 1].plot(r_values, C_r_drift, label=\"With Drift (mu = 0.1)\")\naxs[1, 1].plot(r_values, C_r_standard, label=\"Standard (mu = r)\", linestyle=\"--\")\naxs[1, 1].set_title('Call Option Price vs Risk-Free Interest Rate (r)')\naxs[1, 1].set_xlabel('Risk-Free Interest Rate (r)')\naxs[1, 1].set_ylabel('Call Option Price (P)')\naxs[1, 1].legend()\naxs[1, 1].grid(True)\n\n# Volatility (σ) comparison\naxs[2, 0].plot(sigma_values, C_sigma_drift, label=\"With Drift (mu = 0.1)\")\naxs[2, 0].plot(sigma_values, C_sigma_standard, label=\"Standard (mu = r)\", linestyle=\"--\")\naxs[2, 0].set_title('Call Option Price vs Volatility (σ)')\naxs[2, 0].set_xlabel('Volatility (σ)')\naxs[2, 0].set_ylabel('Call Option Price (P)')\naxs[2, 0].legend()\naxs[2, 0].grid(True)\n\n# Drift (μ) comparison\naxs[2, 1].plot(mu_values, C_mu_drift, label=\"With Drift (mu = varying)\")\naxs[2, 1].plot(mu_values, C_mu_standard, label=\"Standard (mu = r)\", linestyle=\"--\")\naxs[2, 1].set_title('Call Option Price vs Drift (μ)')\naxs[2, 1].set_xlabel('Drift (μ)')\naxs[2, 1].set_ylabel('Call Option Price (P)')\naxs[2, 1].legend()\naxs[2, 1].grid(True)\n\nplt.tight_layout()\nplt.show()\n","key":"CcsCoYdqGw"},{"type":"outputs","id":"lDmfMdviuUEdpAXIdFoOo","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"b943001b0796b61535a083e024d7fe00","path":"/build/b943001b0796b61535a083e024d7fe00.png"},"text/plain":{"content":"<Figure size 1500x1800 with 6 Axes>","content_type":"text/plain"}}},"children":[],"key":"jBjyXLqKAb"}],"key":"qEDw7eKMpN"}],"key":"ETPhwqKMVe"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Using the BSM framework in practice","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"axpuBL46wr"}],"identifier":"using-the-bsm-framework-in-practice","label":"Using the BSM framework in practice","html_id":"using-the-bsm-framework-in-practice","implicit":true,"key":"eTU8z2TNw0"}],"key":"rFLvTTVYDd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport pandas as pd\n\ndef black_scholes_price(S, K, T, r, sigma, option_type='call'):\n    \"\"\"\n    Calculate Black-Scholes option price.\n    \"\"\"\n    d1 = (np.log(S / K) + (r + 0.5 * sigma **2 ) * T ) / (sigma * np.sqrt(T))\n    d2 = d1 - sigma * np.sqrt(T)\n    \n    if option_type == 'call':\n        price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n    elif option_type == 'put':\n        price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n    else:\n        raise ValueError(\"option_type must be 'call' or 'put'\")\n    return price\n\ndef black_scholes_delta(S, K, T, r, sigma, option_type='call'):\n    \"\"\"\n    Calculate Black-Scholes option delta.\n    \"\"\"\n    d1 = (np.log(S / K) + (r + 0.5 * sigma **2 ) * T ) / (sigma * np.sqrt(T))\n    \n    if option_type == 'call':\n        delta = norm.cdf(d1)\n    elif option_type == 'put':\n        delta = norm.cdf(d1) - 1\n    else:\n        raise ValueError(\"option_type must be 'call' or 'put'\")\n    return delta\n\ndef simulate_gbm_paths(S0, mu, sigma, T, dt, n_paths, \n                      stochastic_vol=False, kappa=2.0, theta=0.04, xi=0.2, rho=-0.7):\n    \"\"\"\n    Simulate GBM paths with optional stochastic volatility based on the Heston model.\n    \n    Parameters:\n    - S0: initial stock price\n    - mu: drift\n    - sigma: initial volatility\n    - T: maturity\n    - dt: time step\n    - n_paths: number of simulation paths\n    - stochastic_vol: if True, use the Heston stochastic volatility model\n    - kappa: rate of mean reversion of variance (only if stochastic_vol=True)\n    - theta: long-term variance mean (only if stochastic_vol=True)\n    - xi: volatility of variance (only if stochastic_vol=True)\n    - rho: correlation between stock and variance (only if stochastic_vol=True)\n    \n    Returns:\n    - paths: array of shape (n_steps +1, n_paths)\n    \"\"\"\n    n_steps = int(T / dt)\n    paths = np.zeros((n_steps +1, n_paths))\n    paths[0] = S0\n    \n    if stochastic_vol:\n        # Initialize variance\n        V0 = sigma ** 2\n        variances = np.zeros((n_steps +1, n_paths))\n        variances[0] = V0\n        \n        # Precompute correlation matrix and Cholesky decomposition\n        cov_matrix = np.array([[1.0, rho],\n                               [rho, 1.0]])\n        L = np.linalg.cholesky(cov_matrix)\n        \n        for t in range(1, n_steps +1):\n            # Simulate two correlated random variables\n            Z = np.random.standard_normal((2, n_paths))\n            correlated_Z = L @ Z\n            Z_S = correlated_Z[0]\n            Z_V = correlated_Z[1]\n            \n            # Update variance using CIR process\n            V_prev = variances[t-1]\n            V = V_prev + kappa * (theta - V_prev) * dt + xi * np.sqrt(np.maximum(V_prev, 0)) * np.sqrt(dt) * Z_V\n            V = np.maximum(V, 0)  # Ensure variance is non-negative\n            variances[t] = V\n            \n            # Update stock price\n            S_prev = paths[t-1]\n            S = S_prev * np.exp( (mu - 0.5 * V_prev) * dt + np.sqrt(V_prev) * np.sqrt(dt) * Z_S )\n            paths[t] = S\n    else:\n        for t in range(1, n_steps +1):\n            Z = np.random.standard_normal(n_paths)\n            paths[t] = paths[t-1] * np.exp( (mu - 0.5 * sigma **2 ) * dt + sigma * np.sqrt(dt) * Z )\n    \n    return paths\n\ndef dynamic_hedging(paths, S0, K, T, r, sigma_bs, option_type='call', dt=1/252,\n                   rehedge_freq=1, half_spread=0.0, sigma_sim=None):\n    \"\"\"\n    Implement dynamic hedging strategy.\n    \n    Parameters:\n    - paths: simulated stock price paths (array of shape (n_steps+1, n_paths))\n    - S0: initial stock price\n    - K: strike price\n    - T: maturity\n    - r: risk-free rate\n    - sigma_bs: volatility used in BS model\n    - option_type: 'call' or 'put'\n    - dt: time step size\n    - rehedge_freq: frequency of rehedging in terms of number of steps. If 1, rebalance every step.\n    - half_spread: transaction cost as a fraction of price (half spread for buying and selling)\n    - sigma_sim: volatility used in simulation (if different from sigma_bs)\n    \n    Returns:\n    - differences: array of portfolio - payoff for each path\n    \"\"\"\n    n_steps, n_paths = paths.shape[0]-1, paths.shape[1]\n    # Calculate option price and initial delta\n    option_price = black_scholes_price(S0, K, T, r, sigma_bs, option_type)\n    option_delta = black_scholes_delta(S0, K, T, r, sigma_bs, option_type)\n    \n    # Initialize portfolio\n    portfolio = np.full(n_paths, option_price)\n    stock_position = np.full(n_paths, option_delta)\n    cash_position = portfolio - stock_position * S0\n    \n    # Time steps\n    times = np.linspace(0, T, n_steps +1)\n    \n    # Rehedge steps\n    rehedge_steps = rehedge_freq\n    \n    for t in range(1, n_steps +1):\n        tau = T - times[t]\n        if tau <= 0:\n            tau = 1e-10  # Avoid division by zero\n        \n        # Determine if rebalancing is needed\n        if t % rehedge_steps == 0:\n            # Compute delta using BS formula\n            current_S = paths[t]\n            current_delta = black_scholes_delta(current_S, K, tau, r, sigma_bs, option_type)\n            \n            # Calculate change in delta\n            delta_change = current_delta - stock_position\n            # Calculate transaction cost\n            transaction_cost = half_spread * np.abs(delta_change * current_S)\n            \n            # Update cash position\n            cash_position = cash_position * np.exp(r * dt) - delta_change * current_S - transaction_cost\n            \n            # Update stock position\n            stock_position = current_delta\n        else:\n            # Just grow the cash position\n            cash_position = cash_position * np.exp(r * dt)\n        \n        # Update portfolio value\n        portfolio = cash_position + stock_position * paths[t]\n    \n    # Option payoff\n    if option_type == 'call':\n        payoff = np.maximum(paths[-1] - K, 0)\n    elif option_type == 'put':\n        payoff = np.maximum(K - paths[-1], 0)\n    else:\n        raise ValueError(\"option_type must be 'call' or 'put'\")\n    \n    differences = portfolio - payoff\n    return differences\n\ndef run_simulation():\n    # Parameters\n    S0 = 100          # Initial stock price\n    K = 100           # Strike price\n    T = 1.0           # 1 year\n    r = 0.05          # 5% risk-free rate\n    sigma_bs = 0.20   # 20% volatility used in Black-Scholes model\n    mu = 0.1          # 10% drift\n    option_type = 'call'\n    n_paths = 10000   # Number of simulation paths\n    dt = 1/10000      # Fixed small time step for accurate approximation\n    \n    # Perfect setup with varying rehedging frequency\n    rehedge_freq_values = [1, 10, 100]  # Rebalance every 1, 10, 100 steps\n    differences_rehedge_freq = {}\n    \n    # Simulate perfect hedging with varying rehedging frequencies\n    for freq in rehedge_freq_values:\n        print(f\"Simulating Perfect Setup with Rehedging Frequency: Every {freq} steps\")\n        paths_perfect = simulate_gbm_paths(S0, mu, sigma_bs, T, dt, n_paths, stochastic_vol=False)\n        differences = dynamic_hedging(paths_perfect, S0, K, T, r, sigma_bs, option_type, dt, \n                                     rehedge_freq=freq, half_spread=0.0)\n        differences_rehedge_freq[freq] = differences\n    \n    # Baseline residuals (Rebalance every step)\n    residuals_perfect = differences_rehedge_freq[1]\n    \n    # Violations\n    # 1. Different volatility for simulation (sigma_sim = 0.19 and 0.21)\n    sigma_sim_values = [0.19, 0.21]\n    differences_sigma_sim = {}\n    for sigma_sim in sigma_sim_values:\n        print(f\"Simulating Different Volatility in Simulation: sigma_sim = {sigma_sim}\")\n        paths_diff_vol = simulate_gbm_paths(S0, mu, sigma_sim, T, dt, n_paths, stochastic_vol=False)\n        differences = dynamic_hedging(paths_diff_vol, S0, K, T, r, sigma_bs, option_type, dt, \n                                     rehedge_freq=1, half_spread=0.0)\n        differences_sigma_sim[sigma_sim] = differences\n    \n    # 2. Stochastic Volatility (Heston Model)\n    print(\"Simulating Stochastic Volatility (Heston Model)\")\n    paths_stoch_vol = simulate_gbm_paths(S0, mu, sigma_bs, T, dt, n_paths, stochastic_vol=True,\n                                        kappa=20.0, theta=0.04, xi=0.2, rho=-0.7)\n    differences_stoch_vol = dynamic_hedging(paths_stoch_vol, S0, K, T, r, sigma_bs, option_type, dt, \n                                           rehedge_freq=1, half_spread=0.0)\n    \n    # 3. Transaction Costs (Half Spread = 0.005%)\n    half_spread = 0.00005  # 0.005%\n    print(\"Simulating With Transaction Costs (Half Spread = 0.005%)\")\n    paths_half_spread = simulate_gbm_paths(S0, mu, sigma_bs, T, dt, n_paths, stochastic_vol=False)\n    differences_half_spread = dynamic_hedging(paths_half_spread, S0, K, T, r, sigma_bs, option_type, dt, \n                                             rehedge_freq=1, half_spread=half_spread)\n    \n    # Plot histograms in a 2x2 grid\n    plt.figure(figsize=(18, 14))\n    \n    # Subplot 1: Effect of Re-Hedging Frequency on Hedging Residuals\n    plt.subplot(2, 2, 1)\n    colors = ['blue', 'green', 'red', 'purple']\n    labels = [f'Rebalance Every {freq} Steps' for freq in rehedge_freq_values]\n    \n    for i, freq in enumerate(rehedge_freq_values):\n        plt.hist(differences_rehedge_freq[freq], bins=100, alpha=0.5, \n                 color=colors[i], label=labels[i], density=True)\n    \n    plt.title('Effect of Re-Hedging Frequency on Hedging Residuals')\n    plt.xlabel('Portfolio - Payoff')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 2: Different Volatility in Simulation\n    plt.subplot(2, 2, 2)\n    colors_sigma = ['orange', 'cyan']\n    labels_sigma = [f'sigma_sim = {sigma_sim:.2f}' for sigma_sim in sigma_sim_values]\n    \n    for i, sigma_sim in enumerate(sigma_sim_values):\n        plt.hist(differences_sigma_sim[sigma_sim], bins=100, alpha=0.5, \n                 color=colors_sigma[i], label=labels_sigma[i], density=True)\n    \n    # Add baseline\n    plt.hist(residuals_perfect, bins=100, alpha=0.3, color='black', label='Perfect Replication', density=True)\n    \n    plt.title('Different Volatility in Simulation')\n    plt.xlabel('Portfolio - Payoff')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 3: Stochastic Volatility (Heston Model)\n    plt.subplot(2, 2, 3)\n    plt.hist(differences_stoch_vol, bins=100, alpha=0.7, color='purple', edgecolor='black', density=True, label='Stochastic Volatility')\n    \n    # Add baseline\n    plt.hist(residuals_perfect, bins=100, alpha=0.3, color='black', label='Perfect Replication', density=True)\n    \n    plt.title('Stochastic Volatility (Heston Model)')\n    plt.xlabel('Portfolio - Payoff')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.grid(True)\n    \n    # Subplot 4: Transaction Costs (Half Spread)\n    plt.subplot(2, 2, 4)\n    plt.hist(differences_half_spread, bins=100, alpha=0.7, color='green', edgecolor='black', density=True, label='Half Spread = 0.005%')\n    \n    # Add baseline\n    plt.hist(residuals_perfect, bins=100, alpha=0.3, color='black', label='Perfect Replication', density=True)\n    \n    plt.title('Transaction Costs (Half Spread = 0.005%)')\n    plt.xlabel('Portfolio - Payoff')\n    plt.ylabel('Density')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Summary statistics for Perfect Setup with varied rehedging frequency\n    print(\"Summary Statistics for Perfect Setup with Varied Re-Hedging Frequency:\")\n    for freq, diff in differences_rehedge_freq.items():\n        print(f\"Rebalance Every {freq} Steps: Mean = {np.mean(diff):.6f}, Std Dev = {np.std(diff):.6f}\")\n    print(\"-\"*60)\n    \n    # Summary statistics for Violations\n    print(\"Summary Statistics for Violations:\")\n    \n    # 1. Different Volatility in Simulation\n    for sigma_sim, diff in differences_sigma_sim.items():\n        print(f\"Different Volatility in Simulation (sigma_sim = {sigma_sim:.2f}):\")\n        print(f\"  Mean difference: {np.mean(diff):.6f}\")\n        print(f\"  Std Dev of difference: {np.std(diff):.6f}\")\n    \n    # 2. Stochastic Volatility (Heston Model)\n    print(\"Stochastic Volatility (Heston Model):\")\n    print(f\"  Mean difference: {np.mean(differences_stoch_vol):.6f}\")\n    print(f\"  Std Dev of difference: {np.std(differences_stoch_vol):.6f}\")\n    \n    # 3. Transaction Costs (Half Spread)\n    print(\"Transaction Costs (Half Spread = 0.005%):\")\n    print(f\"  Mean difference: {np.mean(differences_half_spread):.6f}\")\n    print(f\"  Std Dev of difference: {np.std(differences_half_spread):.6f}\")\n    print(\"-\"*40)\n\nif __name__ == \"__main__\":\n    run_simulation()\n","key":"yNPCjoXThY"},{"type":"outputs","id":"2r0zim-TeoLJdKGuQqIH5","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Simulating Perfect Setup with Rehedging Frequency: Every 1 steps\nSimulating Perfect Setup with Rehedging Frequency: Every 10 steps\nSimulating Perfect Setup with Rehedging Frequency: Every 100 steps\nSimulating Different Volatility in Simulation: sigma_sim = 0.19\nSimulating Different Volatility in Simulation: sigma_sim = 0.21\nSimulating Stochastic Volatility (Heston Model)\nSimulating With Transaction Costs (Half Spread = 0.005%)\n"},"children":[],"key":"XVuCgtHdZc"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"3148c4ba80ce7552ab79f8b940948ffa","path":"/build/3148c4ba80ce7552ab79f8b940948ffa.png"},"text/plain":{"content":"<Figure size 1800x1400 with 4 Axes>","content_type":"text/plain"}}},"children":[],"key":"dl9ARqTPRE"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Summary Statistics for Perfect Setup with Varied Re-Hedging Frequency:\nRebalance Every 1 Steps: Mean = 0.000827, Std Dev = 0.068216\nRebalance Every 10 Steps: Mean = 0.003540, Std Dev = 0.214217\nRebalance Every 100 Steps: Mean = -0.011300, Std Dev = 0.690467\n------------------------------------------------------------\nSummary Statistics for Violations:\nDifferent Volatility in Simulation (sigma_sim = 0.19):\n  Mean difference: 0.381420\n  Std Dev of difference: 0.164161\nDifferent Volatility in Simulation (sigma_sim = 0.21):\n  Mean difference: -0.381580\n  Std Dev of difference: 0.172823\nStochastic Volatility (Heston Model):\n  Mean difference: -0.032125\n  Std Dev of difference: 0.193527\nTransaction Costs (Half Spread = 0.005%):\n  Mean difference: -0.152493\n  Std Dev of difference: 0.092860\n----------------------------------------\n"},"children":[],"key":"xGyX6TdMlC"}],"key":"D9ddDA7E7H"}],"key":"tbeCIZGSb2"}],"key":"UEuUwL74f0"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Modelling RfQs in Dealer to Client Markets","url":"/notebooks/rfq-models","group":"Notebooks"}}},"domain":"http://localhost:3001"}